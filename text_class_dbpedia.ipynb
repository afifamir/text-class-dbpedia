{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPom2R7FD+nHHO+vr0kK1gw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afifamir/text-class-dbpedia/blob/main/text_class_dbpedia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c7lUx0ZSy-UA"
      },
      "outputs": [],
      "source": [
        "pip install -U portalocker>=2.0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.datasets import DBpedia\n",
        "\n",
        "train_iter = iter(DBpedia(split=\"train\"))"
      ],
      "metadata": {
        "id": "G9oXEqXvzOzB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KES7NAZKziHR",
        "outputId": "02b3b21c-69b7-4ced-c0e7-ea0759619349"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,\n",
              " 'Toei Bus  The Toei Bus (都営バス Toei Basu) is a bus service operated by the Bus Service Division the Tokyo Metropolitan Bureau of Transportation (東京都交通局 Tōkyō-to Kōtsū-kyoku). It is also called To Bus (都バス To Basu).The bureau mainly operates bus routes in the special wards of Tokyo as well as those in the city of Ōme in the western Tama Area.')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "train_iter = DBpedia(split=\"train\")\n",
        "\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "OYX-3UIwzwnX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['Palestine', 'will', 'be', 'free'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clrxA4RR3qru",
        "outputId": "cb08ef22-9bb5-4a71-ca30-7d1e0615c72b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 776, 95, 676]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1"
      ],
      "metadata": {
        "id": "NcnWdhZg3yPz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline('11')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHDsupsG38q1",
        "outputId": "029c78ac-f023-4d45-b73c-3ca4717ecef8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for _label, _text in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "id": "Dj3qtGLY3_vl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "metadata": {
        "id": "jI4qiZb_4Jjr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "metadata": {
        "id": "h8lAP0KZ4PBZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY2tM4x_4Tra",
        "outputId": "8a9d97df-0b5b-4b0e-b017-8b26a3976ee4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgg2U9aY4b9i",
        "outputId": "30ac045e-2f60-4aaf-ec1a-174530d8c93f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "802998"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc / total_count"
      ],
      "metadata": {
        "id": "534eSLj04eqy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 10  # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64  # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = DBpedia()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
        "        \"valid accuracy {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, accu_val\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtEZK-Eq4izU",
        "outputId": "2a611294-6c14-436f-f4c5-da50e4ba65bb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 8313 batches | accuracy    0.700\n",
            "| epoch   1 |  1000/ 8313 batches | accuracy    0.907\n",
            "| epoch   1 |  1500/ 8313 batches | accuracy    0.939\n",
            "| epoch   1 |  2000/ 8313 batches | accuracy    0.951\n",
            "| epoch   1 |  2500/ 8313 batches | accuracy    0.954\n",
            "| epoch   1 |  3000/ 8313 batches | accuracy    0.961\n",
            "| epoch   1 |  3500/ 8313 batches | accuracy    0.962\n",
            "| epoch   1 |  4000/ 8313 batches | accuracy    0.967\n",
            "| epoch   1 |  4500/ 8313 batches | accuracy    0.970\n",
            "| epoch   1 |  5000/ 8313 batches | accuracy    0.969\n",
            "| epoch   1 |  5500/ 8313 batches | accuracy    0.970\n",
            "| epoch   1 |  6000/ 8313 batches | accuracy    0.973\n",
            "| epoch   1 |  6500/ 8313 batches | accuracy    0.972\n",
            "| epoch   1 |  7000/ 8313 batches | accuracy    0.973\n",
            "| epoch   1 |  7500/ 8313 batches | accuracy    0.973\n",
            "| epoch   1 |  8000/ 8313 batches | accuracy    0.975\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 1748.01s | valid accuracy    0.976 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 8313 batches | accuracy    0.979\n",
            "| epoch   2 |  1000/ 8313 batches | accuracy    0.979\n",
            "| epoch   2 |  1500/ 8313 batches | accuracy    0.978\n",
            "| epoch   2 |  2000/ 8313 batches | accuracy    0.980\n",
            "| epoch   2 |  2500/ 8313 batches | accuracy    0.980\n",
            "| epoch   2 |  3000/ 8313 batches | accuracy    0.981\n",
            "| epoch   2 |  3500/ 8313 batches | accuracy    0.981\n",
            "| epoch   2 |  4000/ 8313 batches | accuracy    0.980\n",
            "| epoch   2 |  4500/ 8313 batches | accuracy    0.981\n",
            "| epoch   2 |  5000/ 8313 batches | accuracy    0.982\n",
            "| epoch   2 |  5500/ 8313 batches | accuracy    0.980\n",
            "| epoch   2 |  6000/ 8313 batches | accuracy    0.982\n",
            "| epoch   2 |  6500/ 8313 batches | accuracy    0.980\n",
            "| epoch   2 |  7000/ 8313 batches | accuracy    0.980\n",
            "| epoch   2 |  7500/ 8313 batches | accuracy    0.981\n",
            "| epoch   2 |  8000/ 8313 batches | accuracy    0.982\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 1751.48s | valid accuracy    0.978 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 8313 batches | accuracy    0.986\n",
            "| epoch   3 |  1000/ 8313 batches | accuracy    0.985\n",
            "| epoch   3 |  1500/ 8313 batches | accuracy    0.985\n",
            "| epoch   3 |  2000/ 8313 batches | accuracy    0.985\n",
            "| epoch   3 |  2500/ 8313 batches | accuracy    0.987\n",
            "| epoch   3 |  3000/ 8313 batches | accuracy    0.984\n",
            "| epoch   3 |  3500/ 8313 batches | accuracy    0.986\n",
            "| epoch   3 |  4000/ 8313 batches | accuracy    0.985\n",
            "| epoch   3 |  4500/ 8313 batches | accuracy    0.986\n",
            "| epoch   3 |  5000/ 8313 batches | accuracy    0.985\n",
            "| epoch   3 |  5500/ 8313 batches | accuracy    0.986\n",
            "| epoch   3 |  6000/ 8313 batches | accuracy    0.985\n",
            "| epoch   3 |  6500/ 8313 batches | accuracy    0.986\n",
            "| epoch   3 |  7000/ 8313 batches | accuracy    0.985\n",
            "| epoch   3 |  7500/ 8313 batches | accuracy    0.985\n",
            "| epoch   3 |  8000/ 8313 batches | accuracy    0.985\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 1757.75s | valid accuracy    0.980 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 8313 batches | accuracy    0.989\n",
            "| epoch   4 |  1000/ 8313 batches | accuracy    0.989\n",
            "| epoch   4 |  1500/ 8313 batches | accuracy    0.989\n",
            "| epoch   4 |  2000/ 8313 batches | accuracy    0.988\n",
            "| epoch   4 |  2500/ 8313 batches | accuracy    0.988\n",
            "| epoch   4 |  3000/ 8313 batches | accuracy    0.989\n",
            "| epoch   4 |  3500/ 8313 batches | accuracy    0.989\n",
            "| epoch   4 |  4000/ 8313 batches | accuracy    0.988\n",
            "| epoch   4 |  4500/ 8313 batches | accuracy    0.988\n",
            "| epoch   4 |  5000/ 8313 batches | accuracy    0.988\n",
            "| epoch   4 |  5500/ 8313 batches | accuracy    0.987\n",
            "| epoch   4 |  6000/ 8313 batches | accuracy    0.987\n",
            "| epoch   4 |  6500/ 8313 batches | accuracy    0.989\n",
            "| epoch   4 |  7000/ 8313 batches | accuracy    0.988\n",
            "| epoch   4 |  7500/ 8313 batches | accuracy    0.989\n",
            "| epoch   4 |  8000/ 8313 batches | accuracy    0.989\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 1848.61s | valid accuracy    0.978 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 8313 batches | accuracy    0.991\n",
            "| epoch   5 |  1000/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  1500/ 8313 batches | accuracy    0.993\n",
            "| epoch   5 |  2000/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  2500/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  3000/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  3500/ 8313 batches | accuracy    0.991\n",
            "| epoch   5 |  4000/ 8313 batches | accuracy    0.993\n",
            "| epoch   5 |  4500/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  5000/ 8313 batches | accuracy    0.993\n",
            "| epoch   5 |  5500/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  6000/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  6500/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  7000/ 8313 batches | accuracy    0.991\n",
            "| epoch   5 |  7500/ 8313 batches | accuracy    0.992\n",
            "| epoch   5 |  8000/ 8313 batches | accuracy    0.992\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 1895.18s | valid accuracy    0.981 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  1000/ 8313 batches | accuracy    0.993\n",
            "| epoch   6 |  1500/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  2000/ 8313 batches | accuracy    0.993\n",
            "| epoch   6 |  2500/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  3000/ 8313 batches | accuracy    0.993\n",
            "| epoch   6 |  3500/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  4000/ 8313 batches | accuracy    0.993\n",
            "| epoch   6 |  4500/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  5000/ 8313 batches | accuracy    0.993\n",
            "| epoch   6 |  5500/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  6000/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  6500/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  7000/ 8313 batches | accuracy    0.993\n",
            "| epoch   6 |  7500/ 8313 batches | accuracy    0.992\n",
            "| epoch   6 |  8000/ 8313 batches | accuracy    0.992\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 1879.27s | valid accuracy    0.981 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  1000/ 8313 batches | accuracy    0.992\n",
            "| epoch   7 |  1500/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  2000/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  2500/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  3000/ 8313 batches | accuracy    0.992\n",
            "| epoch   7 |  3500/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  4000/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  4500/ 8313 batches | accuracy    0.992\n",
            "| epoch   7 |  5000/ 8313 batches | accuracy    0.992\n",
            "| epoch   7 |  5500/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  6000/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  6500/ 8313 batches | accuracy    0.992\n",
            "| epoch   7 |  7000/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  7500/ 8313 batches | accuracy    0.993\n",
            "| epoch   7 |  8000/ 8313 batches | accuracy    0.992\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 1885.63s | valid accuracy    0.981 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  1000/ 8313 batches | accuracy    0.992\n",
            "| epoch   8 |  1500/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  2000/ 8313 batches | accuracy    0.992\n",
            "| epoch   8 |  2500/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  3000/ 8313 batches | accuracy    0.992\n",
            "| epoch   8 |  3500/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  4000/ 8313 batches | accuracy    0.992\n",
            "| epoch   8 |  4500/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  5000/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  5500/ 8313 batches | accuracy    0.992\n",
            "| epoch   8 |  6000/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  6500/ 8313 batches | accuracy    0.992\n",
            "| epoch   8 |  7000/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  7500/ 8313 batches | accuracy    0.993\n",
            "| epoch   8 |  8000/ 8313 batches | accuracy    0.992\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 1893.70s | valid accuracy    0.981 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 8313 batches | accuracy    0.992\n",
            "| epoch   9 |  1000/ 8313 batches | accuracy    0.994\n",
            "| epoch   9 |  1500/ 8313 batches | accuracy    0.993\n",
            "| epoch   9 |  2000/ 8313 batches | accuracy    0.993\n",
            "| epoch   9 |  2500/ 8313 batches | accuracy    0.993\n",
            "| epoch   9 |  3000/ 8313 batches | accuracy    0.992\n",
            "| epoch   9 |  3500/ 8313 batches | accuracy    0.994\n",
            "| epoch   9 |  4000/ 8313 batches | accuracy    0.993\n",
            "| epoch   9 |  4500/ 8313 batches | accuracy    0.992\n",
            "| epoch   9 |  5000/ 8313 batches | accuracy    0.992\n",
            "| epoch   9 |  5500/ 8313 batches | accuracy    0.993\n",
            "| epoch   9 |  6000/ 8313 batches | accuracy    0.992\n",
            "| epoch   9 |  6500/ 8313 batches | accuracy    0.992\n",
            "| epoch   9 |  7000/ 8313 batches | accuracy    0.993\n",
            "| epoch   9 |  7500/ 8313 batches | accuracy    0.993\n",
            "| epoch   9 |  8000/ 8313 batches | accuracy    0.993\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 1893.64s | valid accuracy    0.981 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 8313 batches | accuracy    0.992\n",
            "| epoch  10 |  1000/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  1500/ 8313 batches | accuracy    0.992\n",
            "| epoch  10 |  2000/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  2500/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  3000/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  3500/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  4000/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  4500/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  5000/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  5500/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  6000/ 8313 batches | accuracy    0.992\n",
            "| epoch  10 |  6500/ 8313 batches | accuracy    0.993\n",
            "| epoch  10 |  7000/ 8313 batches | accuracy    0.992\n",
            "| epoch  10 |  7500/ 8313 batches | accuracy    0.992\n",
            "| epoch  10 |  8000/ 8313 batches | accuracy    0.992\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 1915.41s | valid accuracy    0.981 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(\"test accuracy {:8.3f}\".format(accu_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU3nddsPFlrw",
        "outputId": "7a1a5c7d-90eb-4de5-bcb1-b4e2871b9cc6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a class no %s\" % predict(ex_text_str, text_pipeline))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfQ5J-iUF0H6",
        "outputId": "d34d9dbd-b280-47b3-bf63-f4afb2878a7d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a class no 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len('DBpedia')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ91WQzNLpb2",
        "outputId": "d30a901c-811f-40da-a7a3-0b723c526a8c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DBpedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q94PSszQI7V",
        "outputId": "e2058555-509b-4d6b-c46e-0a5dc2772be1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torchtext.datasets.dbpedia.DBpedia(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'test'))>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}